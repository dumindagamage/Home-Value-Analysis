{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# House Price Analytics\n",
        "\n",
        "## 01 Data Extraction and Cleaning\n",
        "\n",
        "**Project:** Code Institute â€“ Capstone Project\n",
        "\n",
        "---\n",
        "### **Objectives**\n",
        "- Load the house dataset from Kaggle: https://www.kaggle.com/datasets/harlfoxem/housesalesprediction \n",
        "- Inspect structure, datatypes, and completeness.\n",
        "- Verify working directory and environment setup.\n",
        "- Handle missing values and remove duplicates.\n",
        "- Handling outliers and anormalies \n",
        "- Statistical analysis\n",
        "- Prepare the dataset for feature engineering and visualisation.\n",
        "\n",
        "### **Inputs**\n",
        "- `data/raw/kc_house_data.csv`\n",
        "\n",
        "### **Outputs**\n",
        "- `data/processed/cleaned_house_data.csv`\n",
        "        \n",
        "### **Additional Comments**\n",
        "Confirm the kc_house_data.csv is exisit under data directory. Run this notebook top-down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup the file and Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ignore warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings \n",
        "# Ignore future warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import nesessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the home directory. Need to change the working directory from its current folder to its parent folder. Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: c:\\MyStuff\\CodeInstitute\\Projects\\ci-project-02\\Home-Value-Analysis\n"
          ]
        }
      ],
      "source": [
        "PROJECT_DIR = os.path.join(os.getcwd(), \"..\") # Define the project root directory\n",
        "os.chdir(PROJECT_DIR) # Change the current working directory to the project root\n",
        "print(\"Working directory:\", os.getcwd()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data from the original data set reside within data directory under data/raw/ directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "Original dataset shape: (21613, 21)\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATASET\n",
        "try:\n",
        "    # Data directory paths\n",
        "    data_path = os.path.join(\"data\", \"raw\")\n",
        "    # Extract the original dataset\n",
        "    df_original = pd.read_csv(os.path.join(data_path, \"kc_house_data.csv\"))\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error loading the dataset.\")\n",
        "    df_original = pd.DataFrame()  # Create an empty DataFrame if loading fails\n",
        "\n",
        "print(f\"Original dataset shape: {df_original.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Data - Initial Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the first 5 rows of the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Quick look at five rows ===\n",
            "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
            "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
            "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
            "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
            "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
            "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
            "\n",
            "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
            "0      5650     1.0           0     0          3      7        1180   \n",
            "1      7242     2.0           0     0          3      7        2170   \n",
            "2     10000     1.0           0     0          3      6         770   \n",
            "3      5000     1.0           0     0          5      7        1050   \n",
            "4      8080     1.0           0     0          3      8        1680   \n",
            "\n",
            "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
            "0              0      1955             0    98178  47.5112 -122.257   \n",
            "1            400      1951          1991    98125  47.7210 -122.319   \n",
            "2              0      1933             0    98028  47.7379 -122.233   \n",
            "3            910      1965             0    98136  47.5208 -122.393   \n",
            "4              0      1987             0    98074  47.6168 -122.045   \n",
            "\n",
            "   sqft_living15  sqft_lot15  \n",
            "0           1340        5650  \n",
            "1           1690        7639  \n",
            "2           2720        8062  \n",
            "3           1360        5000  \n",
            "4           1800        7503  \n"
          ]
        }
      ],
      "source": [
        "# Quick Look \n",
        "print(\"=== Quick look at five rows ===\")\n",
        "with pd.option_context('display.max_columns', None):\n",
        "    print(df_original.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== What are the column name ===\n",
            "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
            "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
            "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
            "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# What are the column name\n",
        "print(\"=== What are the column name ===\")\n",
        "print(df_original.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data count and Data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Data counts ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21613 entries, 0 to 21612\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             21613 non-null  int64  \n",
            " 1   date           21613 non-null  object \n",
            " 2   price          21613 non-null  float64\n",
            " 3   bedrooms       21613 non-null  int64  \n",
            " 4   bathrooms      21613 non-null  float64\n",
            " 5   sqft_living    21613 non-null  int64  \n",
            " 6   sqft_lot       21613 non-null  int64  \n",
            " 7   floors         21613 non-null  float64\n",
            " 8   waterfront     21613 non-null  int64  \n",
            " 9   view           21613 non-null  int64  \n",
            " 10  condition      21613 non-null  int64  \n",
            " 11  grade          21613 non-null  int64  \n",
            " 12  sqft_above     21613 non-null  int64  \n",
            " 13  sqft_basement  21613 non-null  int64  \n",
            " 14  yr_built       21613 non-null  int64  \n",
            " 15  yr_renovated   21613 non-null  int64  \n",
            " 16  zipcode        21613 non-null  int64  \n",
            " 17  lat            21613 non-null  float64\n",
            " 18  long           21613 non-null  float64\n",
            " 19  sqft_living15  21613 non-null  int64  \n",
            " 20  sqft_lot15     21613 non-null  int64  \n",
            "dtypes: float64(5), int64(15), object(1)\n",
            "memory usage: 3.5+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data counts \n",
        "print(\"=== Data counts ===\")\n",
        "print(df_original.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Duplicate Rows: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for Duplicates\n",
        "duplicates = df_original.duplicated().sum()\n",
        "print(f\"\\nDuplicate Rows: {duplicates}\")\n",
        "if duplicates > 0:\n",
        "    df_original = df_original.drop_duplicates()\n",
        "    print(\"Duplicates removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for Missing Values\n",
        "- If there were NaNs, we would impute them.\n",
        "- For skewed data, use Median. For categorical data, use Mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing Values:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "# Check for Missing Values\n",
        "missing = df_original.isnull().sum()\n",
        "print(f\"\\nMissing Values:\\n{missing[missing > 0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations from Initial Data Exploration**\n",
        "\n",
        "- Target Variable: price has been identified as the key dependent variable for our analysis and prediction models.\n",
        "- Numerical Property Characteristics: The dataset includes several continuous and discrete numerical features describing the property structure, specifically bathrooms, sqft_living, sqft_lot, floors, and yr_built.\n",
        "- Categorical Features (Numerically Encoded): Variables such as waterfront, view, condition, and grade are stored as numbers but function as categorical or ordinal data (representing classifications or ratings rather than continuous measurements).\n",
        "- Location Identifiers: Unlike datasets with full addresses, this dataset does not contain street, city, or statezip columns. Instead, analysis will rely on zipcode, lat (latitude), and long (longitude).\n",
        "- No Missing values or Duplicates were found in the data set."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
