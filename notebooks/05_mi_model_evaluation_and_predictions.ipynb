{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# House Price Analytics\n",
        "\n",
        "## 05 Data analysis for generating foresights\n",
        "\n",
        "**Project:** Code Institute â€“ Capstone Project\n",
        "\n",
        "---\n",
        "### **Objectives**\n",
        "- Load the final house dataset\n",
        "- Build a Machine Learning model to predict house prices with high accuracy\n",
        "\n",
        "### **Inputs**\n",
        "- `/data/models/house_price_model.pkl`\n",
        "\n",
        "### **Outputs**\n",
        "- Trained and finetuned Model to power a \"Price Estimator\" dashboard feature that gives Buyers and Sellers a realistic price range (Min, Average, Max).\n",
        "        \n",
        "### **Additional Comments**\n",
        "Confirm the final_house_data.csv is exisit under outputs/datasets. Run this notebook top-down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup the file and Load the Dataset\n",
        "Import nesessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Feature Engine\n",
        "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "# Ignore future warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the home directory. Need to change the working directory from its current folder to its parent folder. Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_DIR = os.path.join(os.getcwd()) # Define the project root directory\n",
        "os.chdir(PROJECT_DIR) # Change the current working directory\n",
        "# Uncomment the line below to verify the current working directory\n",
        "# print(\"Working directory:\", os.getcwd()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data from the original data set reside within data directory under data/processed/ directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "Original dataset shape: (21596, 31)\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATASET\n",
        "try:\n",
        "    # Data directory paths\n",
        "    data_path = os.path.join(\"..\", \"data\", \"processed\")\n",
        "    # Extract the original dataset\n",
        "    df = pd.read_csv(os.path.join(data_path, \"final_house_data.csv\"))\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error loading the dataset.\")\n",
        "    df = pd.DataFrame()  # Create an empty DataFrame if loading fails\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
